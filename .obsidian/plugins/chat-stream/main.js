/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/main.ts
var main_exports = {};
__export(main_exports, {
  default: () => main_default
});
module.exports = __toCommonJS(main_exports);

// src/ChatStreamPlugin.ts
var import_obsidian3 = require("obsidian");

// src/obsidian/obsidian-utils.ts
var addEdge = (canvas, edgeID, fromEdge, toEdge) => {
  if (!canvas)
    return;
  const data = canvas.getData();
  if (!data)
    return;
  canvas.importData({
    "edges": [
      ...data.edges,
      { "id": edgeID, "fromNode": fromEdge.node.id, "fromSide": fromEdge.side, "toNode": toEdge.node.id, "toSide": toEdge.side }
    ],
    "nodes": data.nodes
  });
  canvas.requestFrame();
};

// src/openai/chatGPT.ts
var import_obsidian = require("obsidian");
var CHAT_MODELS = {
  GPT35: {
    name: "gpt-3.5-turbo",
    tokenLimit: 4096
  },
  GPT35_16K: {
    name: "gpt-3.5-turbo-16k",
    tokenLimit: 16384
  },
  GPT4: {
    name: "gpt-4",
    tokenLimit: 8e3
  },
  GPT4_32K: {
    name: "gpt-4-32k",
    tokenLimit: 32768
  }
};
var defaultChatGPTSettings = {
  model: CHAT_MODELS.GPT35.name,
  max_tokens: 500,
  temperature: 0,
  top_p: 1,
  presence_penalty: 0,
  frequency_penalty: 0,
  stop: []
};
async function getChatGPTCompletion(apiKey, model, messages, settings) {
  var _a, _b, _c;
  const apiUrl = `https://api.openai.com/v1/chat/completions`;
  const headers = {
    Authorization: `Bearer ${apiKey}`,
    "Content-Type": "application/json"
  };
  const body = {
    messages,
    model,
    ...settings
  };
  const requestParam = {
    url: apiUrl,
    method: "POST",
    contentType: "application/json",
    body: JSON.stringify(body),
    headers
  };
  console.debug("Calling openAI", requestParam);
  const res = await (0, import_obsidian.request)(requestParam).then((response) => {
    return JSON.parse(response);
  }).catch((err) => {
    console.error(err);
  });
  return (_c = (_b = (_a = res == null ? void 0 : res.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content;
}

// src/settings/ChatStreamSettings.ts
var DEFAULT_SYSTEM_PROMPT = `
You are a critical-thinking assistant bot. 
Consider the intent of my questions before responding.
Do not restate my information unless I ask for it. 
Do not include caveats or disclaimers.
When formatting lists, use bulleted lists (markdown dash character), not numbered lists.
Use step-by-step reasoning. Be brief.
`.trim();
var DEFAULT_SETTINGS = {
  apiKey: "",
  apiModel: CHAT_MODELS.GPT35.name,
  systemPrompt: DEFAULT_SYSTEM_PROMPT,
  debug: false,
  maxInputCharacters: 5e3,
  maxResponseTokens: 0,
  maxDepth: 0
};
function getModels() {
  return Object.entries(CHAT_MODELS).map(([, value]) => value.name);
}

// src/settings/SettingsTab.ts
var import_obsidian2 = require("obsidian");
var SettingsTab = class extends import_obsidian2.PluginSettingTab {
  constructor(app2, plugin) {
    super(app2, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    new import_obsidian2.Setting(containerEl).setName("Model").setDesc("Select the GPT model to use.").addDropdown((cb) => {
      getModels().forEach((model) => {
        cb.addOption(model, model);
      });
      cb.setValue(this.plugin.settings.apiModel);
      cb.onChange(async (value) => {
        this.plugin.settings.apiModel = value;
        await this.plugin.saveSettings();
      });
    });
    new import_obsidian2.Setting(containerEl).setName("API key").setDesc(
      "The API key to use when making requests - Get from OpenAI"
    ).addText(
      (text) => text.setPlaceholder("API Key").setValue(this.plugin.settings.apiKey).onChange(async (value) => {
        this.plugin.settings.apiKey = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian2.Setting(containerEl).setName("System prompt").setDesc("The system prompt sent with each request to the API.").addTextArea((component) => {
      component.inputEl.rows = 6;
      component.inputEl.style.width = "300px";
      component.inputEl.style.fontSize = "10px";
      component.setValue(this.plugin.settings.systemPrompt);
      component.onChange(async (value) => {
        this.plugin.settings.systemPrompt = value;
        await this.plugin.saveSettings();
      });
    });
    new import_obsidian2.Setting(containerEl).setName("Max input characters").setDesc("The maximum number of characters to send to the API (includes system prompt).").addText(
      (text) => text.setValue(this.plugin.settings.maxInputCharacters.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed) && parsed > 0) {
          this.plugin.settings.maxInputCharacters = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian2.Setting(containerEl).setName("Max response tokens").setDesc("The maximum number of _tokens_ to return from the API. 0 means no limit. (A token is about 4 characters).").addText(
      (text) => text.setValue(this.plugin.settings.maxResponseTokens.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed)) {
          this.plugin.settings.maxResponseTokens = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian2.Setting(containerEl).setName("Max depth").setDesc("The maximum depth of ancestor notes to include. 0 means no limit.").addText(
      (text) => text.setValue(this.plugin.settings.maxDepth.toString()).onChange(async (value) => {
        const parsed = parseInt(value);
        if (!isNaN(parsed)) {
          this.plugin.settings.maxDepth = parsed;
          await this.plugin.saveSettings();
        }
      })
    );
    new import_obsidian2.Setting(containerEl).setName("Debug output").setDesc(
      "Enable debug output in the console"
    ).addToggle((component) => {
      component.setValue(this.plugin.settings.debug).onChange(async (value) => {
        this.plugin.settings.debug = value;
        await this.plugin.saveSettings();
      });
    });
  }
};
var SettingsTab_default = SettingsTab;

// src/utils.ts
var randomHexString = (len) => {
  const t = [];
  for (let n = 0; n < len; n++) {
    t.push((16 * Math.random() | 0).toString(16));
  }
  return t.join("");
};

// src/ChatStreamPlugin.ts
var minWidth = 360;
var pxPerChar = 5;
var pxPerLine = 28;
var textPaddingHeight = 12;
var assistantColor = "6";
var newNoteMargin = 60;
var minHeight = 60;
var emptyNoteHeight = 100;
var placeholderNoteHeight = 60;
var ChatStreamPlugin = class extends import_obsidian3.Plugin {
  constructor() {
    super(...arguments);
    this.unloaded = false;
    this.logDebug = () => {
    };
  }
  async onload() {
    await this.loadSettings();
    this.logDebug = this.settings.debug ? (message, ...optionalParams) => console.debug("Chat Stream: " + message, ...optionalParams) : () => {
    };
    this.addSettingTab(new SettingsTab_default(this.app, this));
    this.addCommand({
      id: "next-note",
      name: "Create next note",
      callback: () => {
        this.nextNote();
      },
      hotkeys: [
        {
          modifiers: ["Alt", "Shift"],
          key: "N"
        }
      ]
    });
    this.addCommand({
      id: "generate-note",
      name: "Generate AI note",
      callback: () => {
        this.generateNote();
      },
      hotkeys: [
        {
          modifiers: ["Alt", "Shift"],
          key: "G"
        }
      ]
    });
  }
  onunload() {
    this.unloaded = true;
  }
  async nextNote() {
    if (this.unloaded)
      return;
    this.logDebug("Creating user note");
    const canvas = this.getActiveCanvas();
    if (!canvas) {
      this.logDebug("No active canvas");
      return;
    }
    await canvas.requestFrame();
    const selection = canvas.selection;
    if ((selection == null ? void 0 : selection.size) !== 1)
      return;
    const values = Array.from(selection.values());
    const node = values[0];
    if (node) {
      const created = createNode(canvas, node, { text: "", size: { height: emptyNoteHeight } });
      canvas.selectOnly(
        created,
        true
        /* startEditing */
      );
      await canvas.requestSave();
      await sleep(0);
      created.startEditing();
    }
  }
  async generateNote() {
    var _a, _b, _c;
    if (this.unloaded)
      return;
    if (!this.canCallAI())
      return;
    this.logDebug("Creating AI note");
    const canvas = this.getActiveCanvas();
    if (!canvas) {
      this.logDebug("No active canvas");
      return;
    }
    await canvas.requestFrame();
    const selection = canvas.selection;
    if ((selection == null ? void 0 : selection.size) !== 1)
      return;
    const values = Array.from(selection.values());
    const node = values[0];
    if (node) {
      await canvas.requestSave();
      await sleep(200);
      const settings = this.settings;
      const messages = await buildMessages(node, canvas, settings, this.logDebug);
      if (!messages.length)
        return;
      this.logDebug("Messages for chat API", messages);
      const created = createNode(
        canvas,
        node,
        {
          text: `Calling GPT (${settings.apiModel})...`,
          size: { height: placeholderNoteHeight }
        },
        {
          color: assistantColor,
          chat_role: "assistant"
        }
      );
      new import_obsidian3.Notice(`Sending ${messages.length} notes to GPT`);
      try {
        const generated = await getChatGPTCompletion(
          settings.apiKey,
          settings.apiModel,
          messages,
          {
            max_tokens: settings.maxResponseTokens || void 0
          }
        );
        if (generated == null) {
          new import_obsidian3.Notice(`Empty or unreadable response from GPT`);
          canvas.removeNode(created);
          return;
        }
        created.setText(generated);
        const height = calcHeight({ text: generated, parentHeight: node.height });
        created.moveAndResize({ height, width: created.width, x: created.x, y: created.y });
        const selectedNoteId = ((_a = canvas.selection) == null ? void 0 : _a.size) === 1 ? (_c = (_b = Array.from(canvas.selection.values())) == null ? void 0 : _b[0]) == null ? void 0 : _c.id : void 0;
        if (selectedNoteId === (node == null ? void 0 : node.id) || selectedNoteId == null) {
          canvas.selectOnly(
            created,
            false
            /* startEditing */
          );
        }
      } catch (error) {
        new import_obsidian3.Notice(`Error calling GPT: ${error.message || error}`);
        canvas.removeNode(created);
      }
      await canvas.requestSave();
    }
  }
  getActiveCanvas() {
    const maybeCanvasView = app.workspace.getActiveViewOfType(import_obsidian3.ItemView);
    return maybeCanvasView ? maybeCanvasView["canvas"] : null;
  }
  canCallAI() {
    if (!this.settings.apiKey) {
      new import_obsidian3.Notice("Please set your OpenAI API key in the plugin settings");
      return false;
    }
    return true;
  }
  async loadSettings() {
    this.settings = Object.assign(
      {},
      DEFAULT_SETTINGS,
      await this.loadData()
    );
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
};
async function buildMessages(node, canvas, settings, logDebug) {
  const messages = [];
  let totalLength = 0;
  const visit = async (node2, depth) => {
    if (settings.maxDepth && depth > settings.maxDepth)
      return;
    const nodeData = node2.getData();
    let nodeText = await getNodeText(node2) || "";
    const lengthLimit = settings.maxInputCharacters || DEFAULT_SETTINGS.maxInputCharacters;
    const parents = canvas.getEdgesForNode(node2).filter((edge) => edge.to.node.id === node2.id).map((edge) => edge.from.node);
    if (nodeText.trim()) {
      let textLength = nodeText.length;
      if (totalLength + textLength > lengthLimit) {
        const truncatedLength = lengthLimit - totalLength;
        logDebug(`Truncating node text from ${nodeText.length} to ${truncatedLength} characters`);
        nodeText = nodeText.slice(nodeText.length - truncatedLength);
        textLength = truncatedLength;
      }
      totalLength += textLength;
      let role = nodeData.chat_role === "assistant" ? "assistant" : "user";
      if (parents.length === 0 && nodeText.startsWith("SYSTEM PROMPT")) {
        nodeText = nodeText.slice("SYSTEM PROMPT".length).trim();
        role = "system";
      }
      messages.unshift({
        content: nodeText,
        role
      });
    }
    if (totalLength >= lengthLimit) {
      return;
    }
    for (const parent2 of parents) {
      await visit(parent2, depth + 1);
    }
  };
  await visit(node, 0);
  if (!messages.length)
    return [];
  if (messages[0].role !== "system") {
    messages.unshift({
      content: settings.systemPrompt || DEFAULT_SYSTEM_PROMPT,
      role: "system"
    });
  }
  return messages;
}
async function getNodeText(node) {
  const nodeData = node.getData();
  switch (nodeData.type) {
    case "text":
      return nodeData.text;
    case "file":
      return readFile(nodeData.file);
  }
}
async function readFile(path) {
  const file = this.app.vault.getAbstractFileByPath(path);
  if (file instanceof import_obsidian3.TFile) {
    const body = await app.vault.read(file);
    return `## ${file.basename}
${body}`;
  }
}
var calcHeight = (options) => {
  const calcTextHeight = Math.round(textPaddingHeight + pxPerLine * options.text.length / (minWidth / pxPerChar));
  return Math.max(options.parentHeight, calcTextHeight);
};
var createNode = (canvas, parentNode, nodeOptions, nodeData) => {
  var _a, _b;
  if (!canvas) {
    throw new Error("Invalid arguments");
  }
  const { text } = nodeOptions;
  const width = ((_a = nodeOptions == null ? void 0 : nodeOptions.size) == null ? void 0 : _a.width) || Math.max(minWidth, parentNode == null ? void 0 : parentNode.width);
  const height = ((_b = nodeOptions == null ? void 0 : nodeOptions.size) == null ? void 0 : _b.height) || Math.max(minHeight, parentNode && calcHeight({ text, parentHeight: parentNode.height }));
  const siblings = parent && canvas.getEdgesForNode(parentNode).filter((n) => n.from.node.id == parentNode.id).map((e) => e.to.node);
  const siblingsRight = siblings && siblings.reduce((right, sib) => Math.max(right, sib.x + sib.width), 0);
  const priorSibling = siblings[siblings.length - 1];
  const x = siblingsRight ? siblingsRight + newNoteMargin : parentNode.x;
  const y = (priorSibling ? priorSibling.y : parentNode.y + parentNode.height + newNoteMargin) + height * 0.5;
  const newNode = canvas.createTextNode(
    {
      pos: { x, y },
      position: "left",
      size: { height, width },
      text,
      focus: false
    }
  );
  if (nodeData) {
    newNode.setData(nodeData);
  }
  canvas.deselectAll();
  canvas.addNode(newNode);
  addEdge(canvas, randomHexString(16), {
    fromOrTo: "from",
    side: "bottom",
    node: parentNode
  }, {
    fromOrTo: "to",
    side: "top",
    node: newNode
  });
  return newNode;
};

// src/main.ts
var main_default = ChatStreamPlugin;
