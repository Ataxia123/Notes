## 2. The free energy formulation

The FEP is a mathematical formulation that explains, from first principles, the characteristics of biological systems that are able to resist decay and persist over time. It rests on the idea that all biological systems instantiate a hierarchical generative model of the world that implicitly minimises its internal entropy by minimising free energy. In virtue of the self-organisation inherent in nonequilibrium steady-state, systems will apparently violate the second law of thermodynamics. See Ao et al. [[31]](#br0310) for an interesting treatment of relative entropy in this context (that does not require detailed balance assumptions). From our perspective, this sort of behaviour can be cast in terms of a dynamics (i.e., conservative flow) that appears to minimise a variational free energy, which constitutes an upper bound on the entropy of a system's Markov blanket (see [[32]](#br0320) and Box 2). Technically, free energy is an information theoretic quantity that limits (by being greater than) the entropy of sensory exchanges between a biotic system (e.g., the brain) and the environment. A generative model is a probabilistic mapping from causes in the environment to observed consequences (e.g., sensory data); while entropy refers to the (long-term) average of surprise (or surprisal)—the negative log probability of sensory samples encountered by an agent [[26]](#br0260). Under this formalism, for an organism to resist dissipation and persist as an adaptive system that is part of, coupled with, and yet statistically independent from, the larger system in which it is embedded, it must embody a probabilistic model of the statistical interdependencies and regularities of its environment. We elaborate on this next.

### 2.1. Living systems, ergodicity, and phenotypes

All biological systems exhibit a specific form of self-organisation, which has been sculpted by natural selection to allow them to actively maintain their integrity by revisiting characteristic states within well-defined bounds of their conceivable phase spaces (see Box 1). In other words, there is a high probability that an organism will occupy a relatively small, bounded set of states—its viability set [[33]](#br0330)—within the total set of possible states that it might occupy (i.e., its phase space). In terms of information theory, this means that the probability density function that describes the possible states of the system has low entropy. So, how do living systems perform this feat?

This is simpler than it might seem, and rests on the fact that all living systems revisit a bounded set of states repeatedly (i.e., they are locally ergodic). At every scale—from the oscillations of neuronal activity over milliseconds, through to the pulsations of our heart and our daily routines—we find ourselves in similar states of mind and body. This is the remarkable fact about living systems. All other self-organising systems, from snowflakes to solar systems, follow an inevitable and irreversible path to disorder. Conversely, biological systems are characterised by a random dynamical attractor—a set of attracting states that are frequently revisited. Indeed, the characteristics by which we define living systems are simply statements about the characteristic, attracting states in which we find them [[32]](#br0320). This set of attracting states can be interpreted as the extended phenotype of the organism—its morphology, physiology, behavioural patterns, cultural patterns, and designer environments [[34]](#br0340). This conception of the extended phenotype as the set of attracting states of a coupled dynamical system is supported by evidence from simulation studies of morphogenesis, e.g., [[28]](#br0280). Further supportive evidence comes from studies of cancer genesis and progression, where the success of approaches employing endogenous networks provides a striking example of employing statistical methods (the Markov blanket formalism) to separate internal (phenotypical) states from external ones [[35]](#br0350). This conception of the topology of the phase space is supported by recent work on early myelopoiesis in real biological systems as well [[36]](#br0360). In this study, the core molecular endogenous network under consideration was cast as a set of dynamical equations, yielding structurally robust states that can be interpreted in relation to known cellular phenotypes.

The implications of this are profound. It means that all biotic agents move, systematically, towards attracting states (i.e., those with high probability) to counter the dispersive effects of random fluctuations. Consequently, any living system will appear, on average, to move up the probability gradients that define its attracting set—and the very characteristics responsible for its existence. Thus, living systems do not just destroy energy gradients (by gravitating towards free energy minima), they also create and maintain them by climbing the probability gradients that surround such extrema. In other words, living systems carve out and inhabit minima in free energy landscapes, precluding the dissipation of their states over phase space. This (nonequilibrium steady-state) behaviour differentiates living states from other states, like decay and death [[1]](#br0010), [[37]](#br0370), [[38]](#br0380), [[39]](#br0390). Technically, this gradient-building behaviour can be expressed as the flow over a landscape that corresponds to the log probability of any state being occupied. This probability is also known as ‘Bayesian model evidence’ [[26]](#br0260). This means living systems are effectively self-evidencing—they move to maximise the evidence of their existence [[40]](#br0400). So how do they achieve this?

This is where the FEP comes in. It asserts that all biological systems maintain their integrity by actively reducing the disorder or dispersion (i.e., entropy) of their sensory and physiological states by minimising their variational free energy ([[26]](#br0260); see [Fig. 1](/pmc/articles/PMC5857288/figure/fg0010/) and Box 2). Because the repertoire of functional or adaptive states occupied by an organism is limited, the probability distribution over these characteristic states has low entropy: there is a high probability the organism will revisit a small number of states. Thus, an organism's distal imperative of survival and maintaining functional states within physiological bounds (i.e., homeostasis and allostasis) translates into a proximal avoidance of surprise [[26]](#br0260). Although surprise itself cannot be evaluated, since free energy imposes an upper bound on surprise, biological systems can minimise surprise by minimising their variational free energy. From the point of view of a physicist, surprise corresponds to thermodynamic potential energy [[41]](#br0410), such that minimising (the average) variational free energy entails the minimisation of thermodynamic entropy. Consistent with EST, this propensity to minimise surprise is the result of natural selection (that itself can be seen as a free energy minimising process; see below)—self-organising systems that are able to avoid entropic, internal phase-transitions have been selected over those that could not [[25]](#br1110). This begs the question of how biological systems minimise free energy. To answer this, we will now take a closer look at the relation between surprise and (variational) free energy by introducing the notion of Markov blankets, which is central to the variational neuroethology described later.

[](/pmc/articles/PMC5857288/figure/fg0010/)

[](/pmc/articles/PMC5857288/figure/fg0010/)[

![Fig. 1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5857288//pmc/articles/PMC5857288/bin/gr001.jpg "Click on image to zoom")](/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=5857288_gr001.jpg)

[Open in a separate window](/pmc/articles/PMC5857288/figure/fg0010/?report=objectonly)

[Fig. 1](/pmc/articles/PMC5857288/figure/fg0010/)

The free energy principle. (**A**) Schematic of the quantities that define free-energy. These include the internal states of a system _μ_ (e.g. a brain) and quantities describing exchange with the world; namely, sensory input _s_ = _g_(_η_,_a_)+_ω_ and action _a_ that changes the way the environment is sampled. The environment is described by equations of motion, η˙=f(η,a)+ω, that specify the dynamics of (hidden) states of the world _η_. Here, _ω_ denote random fluctuations. Internal states and action both change to minimise free-energy, which is a function of sensory input and a probabilistic representation (variational density) _q_(_η_:_μ_) encoded by the internal states. (**B**): Alternative expressions for the free-energy illustrating what its minimisation entails. For action, free-energy can only be suppressed by increasing the accuracy of sensory data (i.e., selectively sampling data that are predicted). Conversely, optimising internal states make the representation an approximate conditional density on the causes of sensory input (by minimising divergence). This optimisation makes the free-energy bound on surprise tighter and enables action to avoid surprising sensations.
