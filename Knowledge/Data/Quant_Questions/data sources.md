As a Quant Analyst at a top-tier hedge fund, data sources for token grading and performance prediction are of utmost importance. We rely on a variety of data sources to gather information for this purpose. 

Firstly, we use blockchain data. This includes transaction data, wallet addresses, and other on-chain metrics. This data is publicly available and can provide insights into the behavior of token holders. For example, if a large number of tokens are being moved to exchanges, it could indicate a potential sell-off.

Secondly, we use market data. This includes price, volume, and liquidity data from various cryptocurrency exchanges. This data can help us understand the market dynamics for a particular token. For example, a sudden increase in trading volume could indicate increased interest in the token.

Thirdly, we use social media and news data. This includes sentiment analysis from platforms like Twitter and Reddit, as well as news articles and blog posts. This data can provide insights into the public perception of a token. For example, negative sentiment could indicate a lack of confidence in the token, which could impact its price.

Lastly, we use fundamental data. This includes information about the token's underlying technology, its use case, and its team. This data can help us assess the long-term potential of a token. For example, a token with a strong use case and a competent team could have a higher grade.

However, it's important to note that while these data sources can provide valuable insights, they also have their limitations. For example, market data can be manipulated, social media sentiment can be influenced by bots, and fundamental data can be difficult to verify. Therefore, it's crucial to use a combination of these data sources and to apply rigorous data analysis techniques to ensure the accuracy of our token grading and performance prediction.